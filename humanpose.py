"""HumanPose.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-AMHCfvgpDgUs7HQNqvtqDlAxZZAngu6

## Imports and mounting drive
"""

import torch
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torch, torch.nn as nn
from torch.utils.data import random_split

from dataset import EdgeDataset, PlainDataset, RGBDataset
from models import Unet
from globals import PLAIN_DIR, T, HINT, RGB_CROPS_DIR, EDGE_DETECTION_DIR, MODEL_SAVE_PATH, EPOCHS, BATCH_SIZE

betas = torch.linspace(0.0001, 0.02, T)
alphas = 1-betas
alphas_cumprod = torch.cumprod(alphas, axis=0)
alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)
sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)

def noise_handler(device):

    sqrt_alphas_cumprod_device = sqrt_alphas_cumprod.to(device)
    sqrt_one_minus_alphas_cumprod_device = sqrt_one_minus_alphas_cumprod.to(device)

    def add_noise(x_0, t):
        noise = torch.randn_like(x_0, device=device)
        sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_device[t].view(-1, 1, 1, 1).to(device)
        sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod_device[t].view(-1, 1, 1, 1)
        noisy_img = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise
        return noisy_img, noise
    
    return add_noise


def compute_psnr(img1, img2):
    mse = torch.mean((img1 - img2) ** 2)
    max = 1 # Maximum pixel value
    psnr = 20 * torch.log10(max / torch.sqrt(mse))
    return psnr


# Training loop
def train(model, trainingLoader, validationLoader=None, epochs=10, device="cpu"):

    optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)
    loss_fn = nn.MSELoss()

    trainLosses = [] 
    valLosses = []

    NoiseHandler = noise_handler(device)

    for epoch in range(epochs):

        epochLoss = 0
        model.train()

        for step, batch_data in enumerate(trainingLoader):

            if len(batch_data) == 3:
                hint_batch, clean_heatmap_batch, joint_ids = batch_data
                hint_batch = hint_batch.to(device)
            else:
                clean_heatmap_batch, joint_ids = batch_data
                hint_batch = None
            
            clean_heatmap_batch = clean_heatmap_batch.to(device)
            joint_ids = joint_ids.to(device)

            batch_size = clean_heatmap_batch.shape[0]

            optimiser.zero_grad()
            
            t = torch.randint(0, T, (batch_size,), device=device).long()
            noisy_heatmap, noise = NoiseHandler(clean_heatmap_batch, t)

            if hint_batch is not None:
                model_input = torch.cat((noisy_heatmap, hint_batch), dim=1)            
            else:
                model_input = noisy_heatmap  
                  
            predicted_noise = model(model_input, t, joint_index=joint_ids)
            
            loss = loss_fn(predicted_noise, noise)

            loss.backward()
                                           
            optimiser.step()

            epochLoss += loss.item()

        trainLosses.append(epochLoss / len(trainingLoader))

        model.eval()
        epochValidLoss = 0
        
        with torch.no_grad():
            for batch_data in validationLoader:

                if len(batch_data) == 3:
                    hint_batch, clean_heatmap_batch, joint_ids = batch_data
                    hint_batch = hint_batch.to(device)
                else:
                    clean_heatmap_batch, joint_ids = batch_data
                    hint_batch = None

                clean_heatmap_batch = clean_heatmap_batch.to(device)
                joint_ids = joint_ids.to(device)

                batch_size = clean_heatmap_batch.shape[0]

                t = torch.randint(0, T, (batch_size,), device=device).long()
                noisy_heatmap, noise = NoiseHandler(clean_heatmap_batch, t)
                
                if hint_batch is not None:
                    model_input = torch.cat((noisy_heatmap, hint_batch), dim=1)            
                else:
                    model_input = noisy_heatmap

                predicted_noise = model(model_input, t, joint_index=joint_ids)
                
                loss = loss_fn(predicted_noise, noise)
                epochValidLoss += loss.item()
        
        avg_val_loss = epochValidLoss / len(validationLoader) if len(validationLoader) > 0 else 0
        valLosses.append(avg_val_loss)

        print(f"Epoch {epoch} | Train Loss: {trainLosses[-1]:.6f} | Val Loss: {valLosses[-1]:.6f}")

    return valLosses

def plotValidationLoss(validationLoss):
  plt.plot(validationLoss)
  plt.xlabel("Epochs")
  plt.ylabel("Loss")
  plt.title("Validation Loss")
  plt.show()


def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using {device} device")

    if HINT == "rgb":
        data = RGBDataset(RGB_CROPS_DIR)
        input_channels = 4 # Heatmap + RGB = 4
    elif HINT == "edge":
        data = EdgeDataset(EDGE_DETECTION_DIR)
        input_channels = 2 # Heatmap + Edge = 2
    else:
        data = PlainDataset(PLAIN_DIR)
        input_channels = 1 # Heatmap = 1


    total_size = len(data)
    train_size = int(0.8 * total_size)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = random_split(data, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)

    model = Unet(input_channels=input_channels, output_channels=1, time_dimension=64, num_joints=8).to(device)

    validationLosses = train(model, train_loader, validationLoader=val_loader, epochs=EPOCHS, device=device)

    plotValidationLoss(validationLosses)

    print(f"Saving trained model to {MODEL_SAVE_PATH}")
    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    print("Model saved successfully.")


if __name__ == "__main__":
    main()